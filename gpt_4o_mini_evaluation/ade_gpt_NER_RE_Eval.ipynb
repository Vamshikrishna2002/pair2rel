{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b96221d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bt19d200/NER_Vamshi/NER_Model/.conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be4136a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"ade-benchmark-corpus/ade_corpus_v2\",'Ade_corpus_v2_drug_ade_relation') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd847c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'drug', 'effect', 'indexes'],\n",
       "        num_rows: 6821\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0969bee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Intravenous azithromycin-induced ototoxicity.',\n",
       " 'drug': 'azithromycin',\n",
       " 'effect': 'ototoxicity',\n",
       " 'indexes': {'drug': {'start_char': [12], 'end_char': [24]},\n",
       "  'effect': {'start_char': [33], 'end_char': [44]}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = dataset[\"train\"]\n",
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452e53ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6821/6821 [1:25:24<00:00,  1.33it/s]\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pandas as pd  # make sure df is defined with 'Content' column\n",
    "\n",
    "# Set OpenAI API key\n",
    "client = OpenAI(api_key = \"\")  # Replace with your actual API key\n",
    "\n",
    "# Function: extract named_entities given allowed entity labels\n",
    "def extract_named_entities_by_labels(paragraph, allowed_labels):\n",
    "    allowed_labels_str = \", \".join(allowed_labels)\n",
    "\n",
    "    system_prompt = (\n",
    "        \"You are a named entity recognition (NER) assistant. \"\n",
    "        \"Your task is to extract named entities from a given paragraph, \"\n",
    "        \"but only include entities whose type is one of the following: \"\n",
    "        f\"{allowed_labels_str}. \"\n",
    "        \"Return ONLY a JSON list of entity strings that match the allowed labels. \"\n",
    "        \"Do not include the labels in the output. Keep it JSON parsable.\"\n",
    "    )\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "Paragraph:\n",
    "\n",
    "{paragraph}\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",  # or \"gpt-4o-mini\"\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0.2,\n",
    "        )\n",
    "\n",
    "        reply = response.choices[0].message.content.strip()\n",
    "\n",
    "        if reply.startswith(\"```json\"):\n",
    "            reply = reply[len(\"```json\"):].strip()\n",
    "        if reply.endswith(\"```\"):\n",
    "            reply = reply[:-len(\"```\")].strip()\n",
    "\n",
    "        return json.loads(reply)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error with paragraph:\", paragraph)\n",
    "        print(\"Exception:\", e)\n",
    "        return []\n",
    "\n",
    "    # Example: allowed labels\n",
    "allowed_entity_labels = ['drug','effect']\n",
    "\n",
    "# Loop through DataFrame and extract entities\n",
    "gpt_named_entities = []\n",
    "\n",
    "for i in tqdm(range(len(test))):\n",
    "    paragraph = test[i]['text']\n",
    "    entities = extract_named_entities_by_labels(paragraph, allowed_entity_labels)\n",
    "    gpt_named_entities.append(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45970433",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ade_gpt_named_entities_output.json\", \"w\") as f:\n",
    "    json.dump(gpt_named_entities, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92f92603",
   "metadata": {},
   "outputs": [],
   "source": [
    "true=[]\n",
    "for i in range(len(test)):\n",
    "    temp=[test[i]['drug'],test[i]['effect']]\n",
    "    true.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c365ece2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['naproxen', 'cutaneous fragility']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "087a686b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['naproxen', 'oxaprozin']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_named_entities[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22eee58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_avg=[]\n",
    "precision_avg=[]\n",
    "common2=0\n",
    "for i in range(len(gpt_named_entities)):\n",
    "    true_set=set(true[i])\n",
    "    pred_set=set(gpt_named_entities[i])\n",
    "    \n",
    "    if len(true_set) == 0 and len(pred_set) == 0:\n",
    "        recall_avg.append(1.0)\n",
    "        precision_avg.append(1.0)\n",
    "    else:\n",
    "        count=0\n",
    "        for m in true_set:\n",
    "            for n in pred_set:\n",
    "                if m in n or n in m:\n",
    "                    count+= 1\n",
    "        recall = count / len(true_set) if len(true_set) > 0 else 0\n",
    "        precision = count / len(pred_set) if len(pred_set) > 0 else 0\n",
    "        common2 += count\n",
    "        recall_avg.append(recall)\n",
    "        precision_avg.append(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ba93440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6980647998827152, 0.6144401583853251)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(recall_avg) / len(recall_avg), sum(precision_avg) / len(precision_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef19505b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Intravenous azithromycin-induced ototoxicity.',\n",
       " 'drug': 'azithromycin',\n",
       " 'effect': 'ototoxicity',\n",
       " 'indexes': {'drug': {'start_char': [12], 'end_char': [24]},\n",
       "  'effect': {'start_char': [33], 'end_char': [44]}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "ner=[]\n",
    "for i in range(len(test)):\n",
    "    temp=[]\n",
    "    tokens = re.split(r'[ -.,:;/?\\]\\[]+', test[i]['text'])\n",
    "    drug=re.split(r'[ -.,:;/?\\]\\[]+', test[i]['drug'])\n",
    "    start=tokens.index(drug[0])\n",
    "    end=tokens.index(drug[-1])\n",
    "    temp.append([start,end,'drug',test[i]['drug']])\n",
    "    effect=re.split(r'[ -.,:;/?\\[\\]]+', test[i]['effect'])\n",
    "    start=tokens.index(effect[0])\n",
    "    end=tokens.index(effect[-1])\n",
    "    temp.append([start,end,'effect',test[i]['effect']])\n",
    "    ner.append(temp)\n",
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "956feb60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 'drug', 'azithromycin'], [3, 3, 'effect', 'ototoxicity']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70457c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "relations_true=[]\n",
    "for i in range(len(ner)):\n",
    "    temp=[]\n",
    "    temp.append([ner[i][0][3], ner[i][1][3], 'has'])\n",
    "    relations_true.append(temp)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2295376f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['naproxen', 'pseudoporphyria', 'has']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relations_true[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82893d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6821/6821 [1:51:24<00:00,  1.02it/s]  \n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key = \"\")  # Replace with your actual API key\n",
    "\n",
    "def extract_relation_labels_with_gpt_entities(paragraph, entities, relation_labels):\n",
    "    \"\"\"\n",
    "    Extract RDF triples using GPT-4o/mini with entity spans.\n",
    "\n",
    "    Args:\n",
    "        paragraph (str): Full input paragraph\n",
    "        entities (list): Each entity as [start, end, entity_type, entity_text]\n",
    "        relation_labels (list): Allowed relation labels\n",
    "\n",
    "    Returns:\n",
    "        dict: {\"relation_triples\": [[head, relation, tail], ...]}\n",
    "    \"\"\"\n",
    "    # Convert entity structure into readable text\n",
    "    entity_descs = [\n",
    "        f\"[{start}, {end}, {etype}, {text}]\"\n",
    "        for start, end, etype, text in entities\n",
    "    ]\n",
    "    entity_str = \"\\n\".join(entity_descs)\n",
    "    relation_str = \", \".join(relation_labels)\n",
    "\n",
    "    system_prompt = (\n",
    "        \"You are an expert in information extraction. \"\n",
    "        \"Given a paragraph, a list of named entities with character spans and types, and a list of allowed relation labels, \"\n",
    "        \"extract RDF relation triples in the format [head, relation, tail].\\n\\n\"\n",
    "        \"- Head and tail must be from the provided entity list.\\n\"\n",
    "        \"- The relation must be from the relation_labels list.\\n\"\n",
    "        \"- The output must be ONLY a JSON object like:\\n\"\n",
    "        '{ \"relation_triples\": [ [\"Entity1\", \"Relation\", \"Entity2\"], ... ] }\\n'\n",
    "        \"- Do NOT include any explanation or extra text.\"\n",
    "    )\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "Paragraph:\n",
    "\\\"\\\"\\\"\n",
    "{paragraph}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "Entities (format: [start, end, type, entity]):\n",
    "{entity_str}\n",
    "\n",
    "Relation labels:\n",
    "{relation_str}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",  # or \"gpt-4o-mini\"\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0.2,\n",
    "        )\n",
    "\n",
    "        reply = response.choices[0].message.content.strip()\n",
    "\n",
    "        # Extract JSON block\n",
    "        json_match = re.search(r'\\{.*\\}', reply, re.DOTALL)\n",
    "        if json_match:\n",
    "            json_text = json_match.group(0).strip()\n",
    "            return json.loads(json_text)\n",
    "        else:\n",
    "            print(\"No JSON found.\")\n",
    "            print(\"Reply:\", reply)\n",
    "            return {\"relation_triples\": []}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Exception:\", e)\n",
    "        return {\"relation_triples\": []}\n",
    "gpt_relation_triples = []\n",
    "relation_labels = ['has']\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(test))):\n",
    "    paragraph = test[i]['text']\n",
    "    entities = ner[i]\n",
    "    output= extract_relation_labels_with_gpt_entities(paragraph, entities, relation_labels)\n",
    "    gpt_relation_triples.append(output['relation_triples'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8f9e39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ade_gpt_relation_triples_output.json\", \"w\") as f:\n",
    "    json.dump(gpt_relation_triples, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85beab94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['calcitriol', 'secondary hyperparathyroidism', 'has']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relations_true[6713]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f32c689",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_avg=[]\n",
    "precision_avg=[]\n",
    "common=0\n",
    "ours=0\n",
    "\n",
    "for i in range(len(gpt_relation_triples)):\n",
    "    true_set=relations_true[i]\n",
    "    pred_set=gpt_relation_triples[i]\n",
    "    d={}\n",
    "    for item in pred_set:\n",
    "        if (item[0],item[1]) not in d and (item[1],item[0]) not in d:\n",
    "            d[(item[0],item[1])]=item[2]\n",
    "    \n",
    "    ours+=len(d)\n",
    "    if len(true_set) == 0 and len(pred_set) == 0:\n",
    "        recall_avg.append(1.0)\n",
    "        precision_avg.append(1.0)\n",
    "    else:\n",
    "        count=0\n",
    "        for m in true_set:\n",
    "            for n in pred_set:\n",
    "                if m[0]==n[0] and m[1]==n[2] and (m[2]==n[1]):\n",
    "                    count+= 1\n",
    "        recall = count/ len(true_set) if len(true_set) > 0 else 0\n",
    "        precision = count / len(pred_set) if len(d) > 0 else 0\n",
    "        common += count\n",
    "        recall_avg.append(recall)\n",
    "        precision_avg.append(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6aba707d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9250842984899574, 0.924229096417925)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(recall_avg) / len(recall_avg), sum(precision_avg) / len(precision_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4be9ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bt19d200/NER_Vamshi/NER_Model/.conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "100%|██████████| 6821/6821 [24:31<00:00,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pair2rel import Pair2Rel\n",
    "\n",
    "from tqdm import tqdm\n",
    "model = Pair2Rel.from_pretrained(\"chapalavamshi022/pair2rel\")\n",
    "import torch\n",
    "import re\n",
    "# Force usage of GPU 1\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.device = device \n",
    "relations_all=[]\n",
    "labels = ['has']\n",
    "for i in tqdm(range(len(test))):\n",
    "    # required_labels = []\n",
    "    # for token in processed_data[i]['tokens']:\n",
    "    #     if token in rel_set:\n",
    "    #         required_labels.append(token)\n",
    "    tokens = re.split(r'[ -.,:;/?\\]\\[]+', test[i]['text'])\n",
    "    try:\n",
    "\n",
    "        relations = model.predict_relations(tokens, labels, threshold=0.0, ner=pred_ner[i], top_k=1)\n",
    "\n",
    "        sorted_data_desc = sorted(relations, key=lambda x: x['score'], reverse=True)\n",
    "        temp=[]\n",
    "        for item in sorted_data_desc:\n",
    "            head=' '.join(item['head_text'])\n",
    "            tail=' '.join(item['tail_text'])\n",
    "            if head == tail:\n",
    "                continue\n",
    "            temp.append([head,tail,item['label']])\n",
    "\n",
    "        relations_all.append(temp)\n",
    "    except:\n",
    "        relations_all.append([])\n",
    "        \n",
    "\n",
    "print(\"Success! ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "60fc9ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_avg=[]\n",
    "precision_avg=[]\n",
    "common=0\n",
    "ours=0\n",
    "\n",
    "for i in range(len(relations_all)):\n",
    "    true_set=relations_true[i]\n",
    "    pred_set=relations_all[i]\n",
    "    d={}\n",
    "    for item in pred_set:\n",
    "        if (item[0],item[1]) not in d and (item[1],item[0]) not in d:\n",
    "            d[(item[0],item[1])]=item[2]\n",
    "    \n",
    "    ours+=len(d)\n",
    "    if len(true_set) == 0 and len(pred_set) == 0:\n",
    "        recall_avg.append(1.0)\n",
    "        precision_avg.append(1.0)\n",
    "    else:\n",
    "        count=0\n",
    "        for m in true_set:\n",
    "            for n in pred_set:\n",
    "                if m[0] in n[0] and m[1] in n[1] and (m[2]==n[2]):\n",
    "                    count+= 1\n",
    "        recall = count/ len(true_set) if len(true_set) > 0 else 0\n",
    "        precision = count / len(d) if len(d) > 0 else 0\n",
    "        common += count\n",
    "        recall_avg.append(recall)\n",
    "        precision_avg.append(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a8b08fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6116405219176074, 0.2600283059233326)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(recall_avg) / len(recall_avg), sum(precision_avg) / len(precision_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4895daff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
